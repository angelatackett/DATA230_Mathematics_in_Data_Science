{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelatackett/Mathematics-for-Data-Science---DATA230/blob/main/Essential_Math_for_Data_Science_%5BNield%5D_Chapter_6_Logistic_Regression_%26_Classification_Angela_Tackett.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to your assignment about concepts covered in Chapter 6 of *Essential Math for Data Science* by Thomas Nield. You will be learning about the math in the algorithms of logistic regression and classification.\n",
        "\n",
        "Please read each question carefully and provide detailed explanations for your answers, including any relevant calculations or work. You are also required to provide Python solutions for the technical problems in each question."
      ],
      "metadata": {
        "id": "lgiYK3wfQXjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1"
      ],
      "metadata": {
        "id": "1NPMNlgAQUoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1: Understanding Logistic Regression (One Independent Variable)\n",
        "\n",
        "You are given a dataset containing information about students' exam scores and whether they were admitted to a university or not (1,0).\n",
        "\n",
        "Exam Score: 80, 90, 75, 85, 95, 70, 60, 50, 65, 45\n",
        "\n",
        "Admitted: 1, 1, 1, 1, 1, 0, 0, 0, 0, 0\n",
        "\n",
        "\n",
        "You want to understand the concept of logistic regression and its application in classification tasks.\n",
        "\n",
        "In this solution, we use a logistic regression model to predict the admission status based on the exam scores. We interpret the coefficients and intercept of the logistic regression model to understand their influence on the log-odds. We calculate the predicted probabilities of admission for a few example cases and determine the class predictions. Finally, we evaluate the model's performance using accuracy, precision, recall, and F1-score to assess its effectiveness in classifying admission status."
      ],
      "metadata": {
        "id": "jcOJK71EQi_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Import pandas as pd. Get the logisticregression function from sklearn.linear_model. You need to get train_test_split from sklearn.model_selection and accuracy_score, precision_score, recall_score, and f1_score from sklearn.metrics."
      ],
      "metadata": {
        "id": "4bpcUXTbTfqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "KhvlHg6bTgG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. Load the dataset into a pandas DataFrame. Enter the exam score and admitted status into the dataframe."
      ],
      "metadata": {
        "id": "LezY_fx9Tiio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'ExamScore': [80, 90, 75, 85, 95, 70, 60, 50, 65, 45],\n",
        "    'Admission': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "AjkCAMPDTgYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f470637-7301-412b-dd21-a9c70e247db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ExamScore  Admission\n",
            "0         80          1\n",
            "1         90          1\n",
            "2         75          1\n",
            "3         85          1\n",
            "4         95          1\n",
            "5         70          0\n",
            "6         60          0\n",
            "7         50          0\n",
            "8         65          0\n",
            "9         45          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. Split the dataset into feature matrix X and target variable y. Which variable should be your X value (independent variable). Which variable should be your y value (dependent variable)? *For the X variable, you need to have double brackets to create a Pandas Data Frame versus a series (single brackets)."
      ],
      "metadata": {
        "id": "BncUDesbTg05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['ExamScore']]\n",
        "y = df['Admission']"
      ],
      "metadata": {
        "id": "re9gD7o0Tg90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4. Create an instance of the LogisticRegression model and fit the model."
      ],
      "metadata": {
        "id": "4jiwu-xRThHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Y2ZeVkDKThRg",
        "outputId": "e293db7f-cb23-4bc6-eaac-fa1e98845471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. Interpret the coefficients of the logistic regression model."
      ],
      "metadata": {
        "id": "xvbHNQOCThah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef = model.coef_[0]\n",
        "intercept = model.intercept_"
      ],
      "metadata": {
        "id": "jzLkVqoUThkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6. Calculate the predicted probabilities of admission for example cases.\n",
        " Enter the exams scores of 70, 85, and 95 (replace the ?) to see what the probability of admission is."
      ],
      "metadata": {
        "id": "b2H-Z3VbThtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_cases = [[70], [85], [95]]\n",
        "predicted_probabilities = model.predict_proba(example_cases)\n",
        "\n",
        "for i, case in enumerate(example_cases):\n",
        "    print(f\"Example case {i+1}: Exam Score = {case[0]}, Admission Probability = {predicted_probabilities[i][1]: .3f}\")"
      ],
      "metadata": {
        "id": "Hwg8P9r-Th1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7146264-0173-4b57-8718-6bd8a10b1d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example case 1: Exam Score = 70, Admission Probability =  0.136\n",
            "Example case 2: Exam Score = 85, Admission Probability =  1.000\n",
            "Example case 3: Exam Score = 95, Admission Probability =  1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Step 7. Determine the class predictions based on the predicted probabilities.\n"
      ],
      "metadata": {
        "id": "M7F1in-bUMWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = model.predict(X)"
      ],
      "metadata": {
        "id": "Qqvis-8wUMgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IlEBX7VZ4tIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oLu8AEaQ4r5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8. Evaluate the model's performance."
      ],
      "metadata": {
        "id": "YjprEQnPUMqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y, predicted_classes)\n",
        "precision = precision_score(y, predicted_classes)\n",
        "recall = recall_score(y, predicted_classes)\n",
        "f1 = f1_score(y, predicted_classes)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")"
      ],
      "metadata": {
        "id": "Jf0K4o8IUM2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfbd226-62a8-4d75-ba6f-3ee26bfa5228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the accuracy, precision, recall, and F1-Score of the model? Enter your answer below."
      ],
      "metadata": {
        "id": "XiO99F547R8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your response:   \n",
        "Accuracy: 1.0   \n",
        "Precision: 1.0   \n",
        "Recall: 1.0   \n",
        "F1-Score: 1.0"
      ],
      "metadata": {
        "id": "aFNxZpYW7Xbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2"
      ],
      "metadata": {
        "id": "xWSyysYyQVPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2: Performing a Logistic Regression (Two Independent Variables)\n",
        "\n",
        "You have a dataset containing information about employees in a company, including their age, years of experience, and whether they have left the company or not (1,0).\n",
        "\n",
        "Age: 35, 42, 28, 48, 52, 30, 45, 36, 40, 55\n",
        "\n",
        "Experience: 10, 15, 5, 20, 25, 6, 18, 12, 8, 30\n",
        "\n",
        "Left: 0, 1, 1, 1, 1, 0, 1, 0, 0, 1\n",
        "\n",
        "You want to perform a logistic regression to predict the probability of an employee leaving based on their age and years of experience.\n",
        "\n",
        "In this solution, we perform a logistic regression on the employee dataset to predict the probability of an employee leaving based on their age and years of experience. We split the dataset into training and testing sets using the train_test_split function. Then, we create an instance of the LogisticRegression model and fit it using the training data. Next, we calculate the predicted probabilities of an employee leaving for a few example cases. Finally, we determine the class predictions based on the predicted probabilities and evaluate the model's performance using accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "yYy8Gm-SSG34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Import pandas as pd. Get the logisticregression function from sklearn.linear_model. You need to get train_test_split from sklearn.model_selection and accuracy_score, precision_score, recall_score, and f1_score from sklearn.metrics."
      ],
      "metadata": {
        "id": "uUM5P-w1XuMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "YCmo0ivEXuT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. Load the dataset into a pandas DataFrame. Enter the employee's age, years of experience, and whether they left the compnay or not."
      ],
      "metadata": {
        "id": "wkhkCDq0Xue7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Age': [35, 42, 28, 48, 52, 30, 45, 36, 40, 55],\n",
        "    'Experience': [10, 15, 5, 20, 25, 6, 18, 12, 8, 30],\n",
        "    'Left': [0, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "pK3alakPXuog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. Split the dataset into feature matrix X and target variable y. Which variables should be your X value (independent variables). Which variable should be your y value (dependent variable)? *For the X variables, you need to have double brackets to create a Pandas Data Frame versus a series (single brackets)."
      ],
      "metadata": {
        "id": "uVchn4KHXuzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Age', 'Experience']]\n",
        "y = df['Left']"
      ],
      "metadata": {
        "id": "UReod3gxXu9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4.  Perform train/test split. Use a test size of 20% (0.2)."
      ],
      "metadata": {
        "id": "W6TUMlRuXvKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
      ],
      "metadata": {
        "id": "EN-CjiD9XvUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. Create an instance of the LogisticRegression model and fit the model."
      ],
      "metadata": {
        "id": "BiOJtFCoXvdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3AuMCD0HXvmD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "3982c8b2-8b2f-43f8-e6d8-2cd55762f294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6. Calculate the predicted probabilities of an employee leaving for example cases. Enter three case- age 30 with 6 years experience, age 45 with 18 years of experience, and 55 with 30 years of experience."
      ],
      "metadata": {
        "id": "SggtPoV_XvxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_cases = [[30, 6], [45, 18], [55, 30]]\n",
        "predicted_probabilities = model.predict_proba(example_cases)\n",
        "for i, case in enumerate(example_cases):\n",
        "    print(f\"Example case {i+1}: Age = {case[0]}, Experience = {case[1]}, Probability of Leaving = {predicted_probabilities[i][1]: .3f}\")"
      ],
      "metadata": {
        "id": "wVC2xi_oXv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27a2f58-2c44-4fed-bda2-2cbae2a201aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example case 1: Age = 30, Experience = 6, Probability of Leaving =  0.248\n",
            "Example case 2: Age = 45, Experience = 18, Probability of Leaving =  0.814\n",
            "Example case 3: Age = 55, Experience = 30, Probability of Leaving =  0.972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7. Determine the class predictions based on the predicted probabilities."
      ],
      "metadata": {
        "id": "2ayJjoBPX8zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = model.predict(X_test)"
      ],
      "metadata": {
        "id": "i0B46SZmXwMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Evaluate the model's performance."
      ],
      "metadata": {
        "id": "z9_cSdEUXwYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, predicted_classes)\n",
        "precision = precision_score(y_test, predicted_classes)\n",
        "recall = recall_score(y_test, predicted_classes)\n",
        "f1 = f1_score(y_test, predicted_classes)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1: .3f}\")"
      ],
      "metadata": {
        "id": "33BDGRumXwg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b028607-1f9c-42d8-83af-9d99db2d7617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "F1-Score:  0.667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the accuracy, precision, recall, and F1-Score of the model? Enter your answer below."
      ],
      "metadata": {
        "id": "xNFmFEy-8ApQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your response:  \n",
        "Accuracy: 0.5   \n",
        "Precision: 0.5   \n",
        "Recall: 1.0  \n",
        "F1-Score:  0.667"
      ],
      "metadata": {
        "id": "Qrw8YjP68CcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3"
      ],
      "metadata": {
        "id": "zgMCg67ASQfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3: Multiple Logistic Regression\n",
        "\n",
        "You have a dataset containing information about students, including their exam scores, hours studied, and whether they passed the exam or not.\n",
        "\n",
        "Exam Score: 80, 90, 75, 85, 95, 70, 60, 50, 65, 45\n",
        "\n",
        "Hours Studied: 5, 6, 7, 6, 7, 8, 7, 9, 4, 6\n",
        "\n",
        "Passed exam: 1, 1, 1, 1, 1, 0, 0, 0, 0, 0\n",
        "\n",
        "You want to perform a multivariable logistic regression to predict the probability of a student passing the exam based on their exam scores and hours studied.\n",
        "\n",
        "In this solution, we perform a multivariable logistic regression on the student dataset to predict the probability of a student passing the exam based on their exam scores and hours studied. We create an instance of the LogisticRegression model and fit it using the feature matrix X and the target variable y. Then, we calculate the predicted probabilities of passing the exam for a few example cases. Next, we determine the class predictions based on the predicted probabilities. Finally, we evaluate the model's performance using accuracy, precision, recall, and F1-score to assess its effectiveness in predicting the exam pass status based on exam scores and hours studied."
      ],
      "metadata": {
        "id": "UROXwgklSTzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Import pandas as pd. Get the logisticregression function from sklearn.linear_model. You need to get accuracy_score, precision_score, recall_score, and f1_score from sklearn.metrics."
      ],
      "metadata": {
        "id": "XAvcTMnnDiAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "JzTmU6hFDiLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. Load the dataset into a pandas DataFrame"
      ],
      "metadata": {
        "id": "fs6PZCVHDiWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'ExamScores': [80, 90, 75, 85, 95, 70, 60, 50, 65, 45],\n",
        "    'HoursStudied': [5, 6, 7, 6, 7, 8, 7, 9, 4, 6],\n",
        "    'Pass': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "ihsjPJd5DihO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. Split the dataset into feature matrix X and target variable y. Which variables should be your X value (independent variables). Which variable should be your y value (dependent variable)? *For the X variables, you need to have double brackets to create a Pandas Data Frame versus a series (single brackets)."
      ],
      "metadata": {
        "id": "iDDSzN8DDiq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['ExamScores','HoursStudied']]\n",
        "y = df['Pass']\n",
        "print(df)"
      ],
      "metadata": {
        "id": "kwH_1vI3Di3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36de583-ca04-455f-e573-358a059b4cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ExamScores  HoursStudied  Pass\n",
            "0          80             5     1\n",
            "1          90             6     1\n",
            "2          75             7     1\n",
            "3          85             6     1\n",
            "4          95             7     1\n",
            "5          70             8     0\n",
            "6          60             7     0\n",
            "7          50             9     0\n",
            "8          65             4     0\n",
            "9          45             6     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4. Create an instance of the LogisticRegression model and fit the model using x and y."
      ],
      "metadata": {
        "id": "-4-L71rADjDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "ucpcZcmzDjOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f4a467fe-c247-42f7-b043-d33419fa8005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. Calculate the predicted probabilities of passing the exam for example cases. The example cases are a student with a score of 70, studied 8 hours; a student with a score of 85, studied 6 hours; and a student with a score of 90, studied 7 hours."
      ],
      "metadata": {
        "id": "hRkInLWNDjYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_cases = [[70, 8], [85, 6], [90, 7]]\n",
        "predicted_probabilities = model.predict_proba(example_cases)\n",
        "\n",
        "for i, case in enumerate(example_cases):\n",
        "    print(f\"Example case {i+1}: Exam Scores = {case[0]}, Hours Studied = {case[1]}, Probability of Passing = {predicted_probabilities[i][1]: .3f}\")"
      ],
      "metadata": {
        "id": "Visxz9njDjlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151590b5-85ec-4b15-bbab-61df7f2bb505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example case 1: Exam Scores = 70, Hours Studied = 8, Probability of Passing =  0.130\n",
            "Example case 2: Exam Scores = 85, Hours Studied = 6, Probability of Passing =  1.000\n",
            "Example case 3: Exam Scores = 90, Hours Studied = 7, Probability of Passing =  1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6. Determine the class predictions based on the predicted probabilities."
      ],
      "metadata": {
        "id": "Te8sh30IDjwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = model.predict(X)"
      ],
      "metadata": {
        "id": "nQwENMYyFnLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7. Evaluate the model's performance"
      ],
      "metadata": {
        "id": "PjDJQxv2FmtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y, predicted_classes)\n",
        "precision = precision_score(y, predicted_classes)\n",
        "recall = recall_score(y, predicted_classes)\n",
        "f1 = f1_score(y, predicted_classes)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1: .3f}\")"
      ],
      "metadata": {
        "id": "Kqd7wHGJDj3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3394192-f550-47a1-c81b-ebc96dadd5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score:  1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the accuracy, precision, recall, and F1-Score of the model? Enter your answer below."
      ],
      "metadata": {
        "id": "T143P5h_8vwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter your response:  \n",
        "Accuracy: 1.0  \n",
        "Precision: 1.0  \n",
        "Recall: 1.0  \n",
        "F1-Score:  1.000"
      ],
      "metadata": {
        "id": "CUQhoDsI8yVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4: Multiple Logistic Regression for Customer Attrition Prediction\n",
        "\n",
        "Objective: Build a logistic regression model to predict the chance of attrition for a given customer using multiple predictor variables.\n",
        "\n",
        "Dataset: Fiberbits/Fiberbits.csv\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. The dependent variable is binary, representing whether the customer is active or has already left the network.\n",
        "2. The model should consider multiple predictor variables such as age, gender, place, income, etc., to predict customer attrition.\n",
        "3. Implement the logistic regression using the provided dataset.\n",
        "Evaluate the model's performance to assess how well it predicts customer attrition.\n",
        "4. Identify and discuss the most impacting variables on customer attrition based on the logistic regression analysis.\n",
        "\n",
        "Note: Make use of the provided dataset and libraries like pandas, sklearn, and statsmodels for data loading, modeling, and analysis. Provide clear explanations of the steps taken and the interpretation of the results.\n",
        "\n",
        "Hints for reading the file:\n",
        "1. Go to https://github.com/usharanijk/datascience/blob/main/Fiberbits.csv to download the dataset file\n",
        "2. Upload the Fiberbits.csv to your \"My Drive\", on the upper left corner of your personal Google Drive, then use the following code to load it to your program for the multiple logistic analysis\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Fiberbits.csv'\n",
        "\n",
        "Fiber = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "r1PBrHvN_WJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. Import pandas as pd, matplotlib.pyplot as plt, and statsmodels.api as sm. From sklearn.linear_model import LogisticRegression. From sklearn.metrics, import confusion_matrix."
      ],
      "metadata": {
        "id": "uF_TZUjaH4lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "8wiC7QyJH425"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. Access the data on google drive."
      ],
      "metadata": {
        "id": "BJPsK-PNH57x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLrbnfqeH6LS",
        "outputId": "170fe4ca-40fc-41e3-d9c7-2cfd432c222b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. Load the dataset. Make sure you have downloaded the file from the provided website and uploaded into \"MyDrive\"."
      ],
      "metadata": {
        "id": "D9ZJKDvIH6zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Fiberbits.csv'\n",
        "Fiber = pd.read_csv(file_path)\n",
        "\n",
        "list(Fiber.columns.values)"
      ],
      "metadata": {
        "id": "UnE0gNUuH6-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2483b0-a902-4423-c36f-feab814432a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['active_cust',\n",
              " 'income',\n",
              " 'months_on_network',\n",
              " 'Num_complaints',\n",
              " 'number_plan_changes',\n",
              " 'relocated',\n",
              " 'monthly_bill',\n",
              " 'technical_issues_per_month',\n",
              " 'Speed_test_result']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4. Build a model to predict the chance of attrition for a given customer using all the features."
      ],
      "metadata": {
        "id": "13lC0836H8qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic = LogisticRegression(max_iter=300)\n",
        "logistic.fit(Fiber[[\"income\"] + ['months_on_network'] + ['Num_complaints'] + ['number_plan_changes'] +\n",
        "                 ['relocated'] + ['monthly_bill'] + ['technical_issues_per_month'] + ['Speed_test_result']],\n",
        "             Fiber['active_cust'])\n",
        "\n",
        "predict1 = logistic.predict(Fiber[[\"income\"] + ['months_on_network'] + ['Num_complaints'] + ['number_plan_changes'] +\n",
        "                                  ['relocated'] + ['monthly_bill'] + ['technical_issues_per_month'] +\n",
        "                                  ['Speed_test_result']])"
      ],
      "metadata": {
        "id": "lpDfQqKoH8z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. Create a confusion matrix to evaluate your model"
      ],
      "metadata": {
        "id": "uDmbo-k2H-Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm1 = confusion_matrix(Fiber[['active_cust']], predict1)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.imshow(cm1)\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm1[i, j], ha='center', va='center', color='red')\n",
        "plt.show()\n",
        "\n",
        "total1 = sum(sum(cm1))\n",
        "accuracy1 = (cm1[0, 0] + cm1[1, 1]) / total1\n",
        "print(\"The accuracy of the model is\", accuracy1)"
      ],
      "metadata": {
        "id": "ViD1WS6SH-h6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "outputId": "284ef103-5803-4700-94d3-f1b976cd8976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is 0.74863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6. Which variables are most impactful?"
      ],
      "metadata": {
        "id": "K8QlREXLH-qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit1 = sm.Logit(Fiber['active_cust'],\n",
        "                  Fiber[['income'] + ['months_on_network'] + ['Num_complaints'] + ['number_plan_changes'] +\n",
        "                        ['relocated'] + ['monthly_bill'] + ['technical_issues_per_month'] + ['Speed_test_result']])\n",
        "\n",
        "result1 = logit1.fit()\n",
        "result1.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "MeTfZdUdH-yC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "7c5fdac9-728b-4aaf-9743-c245b50516bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.517172\n",
            "         Iterations 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:            active_cust   No. Observations:               100000\n",
              "Model:                          Logit   Df Residuals:                    99992\n",
              "Method:                           MLE   Df Model:                            7\n",
              "Date:                Sun, 03 Dec 2023   Pseudo R-squ.:                  0.2403\n",
              "Time:                        04:09:53   Log-Likelihood:                -51717.\n",
              "converged:                       True   LL-Null:                       -68074.\n",
              "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
              "==============================================================================================\n",
              "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "----------------------------------------------------------------------------------------------\n",
              "income                       1.71e-05   4.17e-06      4.097      0.000    8.92e-06    2.53e-05\n",
              "months_on_network              0.0150      0.000     31.172      0.000       0.014       0.016\n",
              "Num_complaints                -1.7669      0.027    -65.284      0.000      -1.820      -1.714\n",
              "number_plan_changes           -0.1784      0.007    -23.909      0.000      -0.193      -0.164\n",
              "relocated                     -3.0826      0.040    -76.259      0.000      -3.162      -3.003\n",
              "monthly_bill                  -0.0024      0.000    -16.014      0.000      -0.003      -0.002\n",
              "technical_issues_per_month    -0.4636      0.007    -64.010      0.000      -0.478      -0.449\n",
              "Speed_test_result              0.1094      0.001     75.073      0.000       0.107       0.112\n",
              "==============================================================================================\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>active_cust</td>   <th>  No. Observations:  </th>  <td>100000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 99992</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Sun, 03 Dec 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.2403</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>04:09:53</td>     <th>  Log-Likelihood:    </th> <td> -51717.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -68074.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>income</th>                     <td>  1.71e-05</td> <td> 4.17e-06</td> <td>    4.097</td> <td> 0.000</td> <td> 8.92e-06</td> <td> 2.53e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>months_on_network</th>          <td>    0.0150</td> <td>    0.000</td> <td>   31.172</td> <td> 0.000</td> <td>    0.014</td> <td>    0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Num_complaints</th>             <td>   -1.7669</td> <td>    0.027</td> <td>  -65.284</td> <td> 0.000</td> <td>   -1.820</td> <td>   -1.714</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>number_plan_changes</th>        <td>   -0.1784</td> <td>    0.007</td> <td>  -23.909</td> <td> 0.000</td> <td>   -0.193</td> <td>   -0.164</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>relocated</th>                  <td>   -3.0826</td> <td>    0.040</td> <td>  -76.259</td> <td> 0.000</td> <td>   -3.162</td> <td>   -3.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>monthly_bill</th>               <td>   -0.0024</td> <td>    0.000</td> <td>  -16.014</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>technical_issues_per_month</th> <td>   -0.4636</td> <td>    0.007</td> <td>  -64.010</td> <td> 0.000</td> <td>   -0.478</td> <td>   -0.449</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Speed_test_result</th>          <td>    0.1094</td> <td>    0.001</td> <td>   75.073</td> <td> 0.000</td> <td>    0.107</td> <td>    0.112</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}                &   active\\_cust   & \\textbf{  No. Observations:  } &   100000    \\\\\n\\textbf{Model:}                        &      Logit       & \\textbf{  Df Residuals:      } &    99992    \\\\\n\\textbf{Method:}                       &       MLE        & \\textbf{  Df Model:          } &        7    \\\\\n\\textbf{Date:}                         & Sun, 03 Dec 2023 & \\textbf{  Pseudo R-squ.:     } &   0.2403    \\\\\n\\textbf{Time:}                         &     04:09:53     & \\textbf{  Log-Likelihood:    } &   -51717.   \\\\\n\\textbf{converged:}                    &       True       & \\textbf{  LL-Null:           } &   -68074.   \\\\\n\\textbf{Covariance Type:}              &    nonrobust     & \\textbf{  LLR p-value:       } &    0.000    \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                                       & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{income}                        &     1.71e-05  &     4.17e-06     &     4.097  &         0.000        &     8.92e-06    &     2.53e-05     \\\\\n\\textbf{months\\_on\\_network}           &       0.0150  &        0.000     &    31.172  &         0.000        &        0.014    &        0.016     \\\\\n\\textbf{Num\\_complaints}               &      -1.7669  &        0.027     &   -65.284  &         0.000        &       -1.820    &       -1.714     \\\\\n\\textbf{number\\_plan\\_changes}         &      -0.1784  &        0.007     &   -23.909  &         0.000        &       -0.193    &       -0.164     \\\\\n\\textbf{relocated}                     &      -3.0826  &        0.040     &   -76.259  &         0.000        &       -3.162    &       -3.003     \\\\\n\\textbf{monthly\\_bill}                 &      -0.0024  &        0.000     &   -16.014  &         0.000        &       -0.003    &       -0.002     \\\\\n\\textbf{technical\\_issues\\_per\\_month} &      -0.4636  &        0.007     &   -64.010  &         0.000        &       -0.478    &       -0.449     \\\\\n\\textbf{Speed\\_test\\_result}           &       0.1094  &        0.001     &    75.073  &         0.000        &        0.107    &        0.112     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Logit Regression Results}\n\\end{center}"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the accuracy in % of the model? What are the two impacting variables? What are the two least impacting variables? Hint, what is the absolute value of the z score of each variable? This will tell you if it has an impact. Enter your response in the text box below."
      ],
      "metadata": {
        "id": "ZwrhVsxfH-5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter the accuracy, top two impacting variables, and bottom two impacting variables:"
      ],
      "metadata": {
        "id": "lQTy0dsN3861"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: 74.863%    \n",
        "\n",
        "Two Highest Impact:  \n",
        "- relocated\n",
        "- Speed_test_result\n",
        "  \n",
        "Two Lowest Impact:  \n",
        "- income\n",
        "- monthly_bill\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Eg0Fo3c04YPw"
      }
    }
  ]
}